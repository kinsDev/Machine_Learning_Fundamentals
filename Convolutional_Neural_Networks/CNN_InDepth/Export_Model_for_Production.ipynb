{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Production-Ready Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98088de835752bdb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "testval_transforms = T.Compose(\n",
    "    [\n",
    "        # The size here depends on your application. Here let's use 256x256\n",
    "        T.Resize(256),\n",
    "        # Let's take the central 224x224 part of the image\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0636cc835035298"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We need to wrap our model in a wrapper class that is going to take care of applying the transformations and then run the transformed image through the CNN.\n",
    "\n",
    "If we trained with the nn.CrossEntropyLoss as the loss function, we also need to apply a softmax function to the output of the model so that the output of the wrapper will be probabilities and not merely scores.\n",
    "\n",
    "Let's see an example of such a wrapper class:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8900aa16ce825ba0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "from __future__ import annotations\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model: nn.Module,\n",
    "            class_names: list[str],\n",
    "            mean: torch.Tensor,\n",
    "            std: torch.Tensor\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model.eval()\n",
    "        self.class_names = class_names\n",
    "\n",
    "        self.transforms = nn.Sequential(\n",
    "            T.Resize([256, ]),\n",
    "            T.CenterCrop(224),\n",
    "            T.ConvertImageDtype(torch.float),\n",
    "            T.Normalize(mean.tolist(), std.tolist())\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            # 1. apply transforms\n",
    "            x = self.transforms(x)  # =\n",
    "            # 2. get the logits\n",
    "            x = self.model(x)  # =\n",
    "            # 3. apply softmax\n",
    "            #    HINT: remmeber to apply softmax across dim=1\n",
    "            x = F.softmax(x, dim=1)  # =\n",
    "\n",
    "            return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3455009176e25fe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Constructor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95b3026558647ea7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "self.transforms = nn.Sequential(\n",
    "    T.Resize([256, ]),  # We use single int value inside a list due to torchscript type restrictions\n",
    "    T.CenterCrop(224),\n",
    "    T.ConvertImageDtype(torch.float),\n",
    "    T.Normalize(mean.tolist(), std.tolist())\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a55d7328f66bcaee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The forward Method"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffd60e2eddde3dd0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    with torch.no_grad():\n",
    "        # 1. apply transforms\n",
    "        x = self.transforms(x)  # =\n",
    "        # 2. get the logits\n",
    "        x = self.model(x)  # =\n",
    "        # 3. apply softmax\n",
    "        #    HINT: remmeber to apply softmax across dim=1\n",
    "        x = F.softmax(x, dim=1)  # =\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b3f652bc90a46a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export Using torchscript"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd82c6ab4ce4d9aa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predictor = Predictor(model, class_names, mean, std).cpu()\n",
    "\n",
    "# Export using torch.jit.script\n",
    "scripted_predictor = torch.jit.script(predictor)\n",
    "scripted_predictor.save(\"standalone_model.pt\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52e2a172205e2f02"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# All together the code will be:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36ab7ee752484d79"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Reload the model\n",
    "learn_inf = torch.jit.load(\"standalone_model.pt\")\n",
    "\n",
    "# Read an image and transform it to tensor to simulate what would\n",
    "# happen in production\n",
    "img = Image.open(\"static_images/test/09.Golden_Gate_Bridge/190f3bae17c32c37.jpg\")\n",
    "# We use .unsqueeze because the model expects a batch, so this\n",
    "# creates a batch of 1 element\n",
    "pil_to_tensor = T.ToTensor()(img).unsqueeze_(0)\n",
    "\n",
    "# Perform inference and get the softmax vector\n",
    "softmax = predictor_reloaded(pil_to_tensor).squeeze()\n",
    "# Get index of the winning label\n",
    "max_idx = softmax.argmax()\n",
    "# Print winning label using the class_names attribute of the \n",
    "# model wrapper\n",
    "print(f\"Prediction: {learn_inf.class_names[max_idx]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84461df4571940d5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
