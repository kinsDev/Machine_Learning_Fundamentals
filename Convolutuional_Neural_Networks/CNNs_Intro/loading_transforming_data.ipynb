{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LOADING DATA & Transforming Images in PyTorch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abc2c488eacda25d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Update the PATH to include the user installation directory. \n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['PATH']}:/root/.local/bin\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T08:42:26.410460900Z",
     "start_time": "2024-06-10T08:42:26.392913400Z"
    }
   },
   "id": "308e609f88dcc831",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\TorchTensor\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "from torchvision import datasets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T08:42:30.153803900Z",
     "start_time": "2024-06-10T08:42:27.910879600Z"
    }
   },
   "id": "d106fd4cb4265db1",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## T.Compose creates a pipeline where the provided\n",
    "## transformations are run in sequence\n",
    "\n",
    "transforms = T.Compose(\n",
    "    [\n",
    "        # This transforms takes a np.array or a PIL image of integers\n",
    "        # in the range 0-255 and transforms it to a float tensor in the\n",
    "        # range 0.0 - 1.0\n",
    "        T.ToTensor(),\n",
    "\n",
    "        # This then renormalizes the tensor to be between -1.0 and 1.0,\n",
    "        # which is a better range for modern activation functions like\n",
    "        # Relu\n",
    "        T.Normalize((0.5), (0.5)),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T08:42:34.370513400Z",
     "start_time": "2024-06-10T08:42:34.336352Z"
    }
   },
   "id": "4c673c04518cb4ab",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /.data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /.data\\MNIST\\raw\\train-images-idx3-ubyte.gz to /.data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /.data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /.data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to /.data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /.data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /.data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to /.data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /.data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /.data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to /.data\\MNIST\\raw\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST( root = \"/.data\", train = True, download = True, transform = transforms)\n",
    "\n",
    "test_data = datasets.MNIST( root = \"/.data\", train = False, download = True, transform = transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T08:42:56.928463Z",
     "start_time": "2024-06-10T08:42:36.099154400Z"
    }
   },
   "id": "199c8ce94cec5399",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/data/custom_data'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m train_data \u001B[38;5;241m=\u001B[39m \u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mImageFolder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/data/custom_data\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtransforms\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\TorchTensor\\lib\\site-packages\\torchvision\\datasets\\folder.py:309\u001B[0m, in \u001B[0;36mImageFolder.__init__\u001B[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001B[0m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    302\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    303\u001B[0m     root: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    307\u001B[0m     is_valid_file: Optional[Callable[[\u001B[38;5;28mstr\u001B[39m], \u001B[38;5;28mbool\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    308\u001B[0m ):\n\u001B[1;32m--> 309\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mIMG_EXTENSIONS\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_transform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_transform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_valid_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimgs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\TorchTensor\\lib\\site-packages\\torchvision\\datasets\\folder.py:144\u001B[0m, in \u001B[0;36mDatasetFolder.__init__\u001B[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001B[0m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    135\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    136\u001B[0m     root: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    141\u001B[0m     is_valid_file: Optional[Callable[[\u001B[38;5;28mstr\u001B[39m], \u001B[38;5;28mbool\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    142\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(root, transform\u001B[38;5;241m=\u001B[39mtransform, target_transform\u001B[38;5;241m=\u001B[39mtarget_transform)\n\u001B[1;32m--> 144\u001B[0m     classes, class_to_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_classes\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroot\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    145\u001B[0m     samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_dataset(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot, class_to_idx, extensions, is_valid_file)\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader \u001B[38;5;241m=\u001B[39m loader\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\TorchTensor\\lib\\site-packages\\torchvision\\datasets\\folder.py:218\u001B[0m, in \u001B[0;36mDatasetFolder.find_classes\u001B[1;34m(self, directory)\u001B[0m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_classes\u001B[39m(\u001B[38;5;28mself\u001B[39m, directory: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[List[\u001B[38;5;28mstr\u001B[39m], Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m]]:\n\u001B[0;32m    192\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001B[39;00m\n\u001B[0;32m    193\u001B[0m \n\u001B[0;32m    194\u001B[0m \u001B[38;5;124;03m        directory/\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001B[39;00m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfind_classes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\TorchTensor\\lib\\site-packages\\torchvision\\datasets\\folder.py:40\u001B[0m, in \u001B[0;36mfind_classes\u001B[1;34m(directory)\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_classes\u001B[39m(directory: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[List[\u001B[38;5;28mstr\u001B[39m], Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m]]:\n\u001B[0;32m     36\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \n\u001B[0;32m     38\u001B[0m \u001B[38;5;124;03m    See :class:`DatasetFolder` for details.\u001B[39;00m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 40\u001B[0m     classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(entry\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m entry \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscandir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m entry\u001B[38;5;241m.\u001B[39mis_dir())\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m classes:\n\u001B[0;32m     42\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find any class folder in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdirectory\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] The system cannot find the path specified: '/data/custom_data'"
     ]
    }
   ],
   "source": [
    "train_data = datasets.ImageFolder(\n",
    "    \"/data/custom_data\",\n",
    "    transform = transforms\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T08:48:11.351175900Z",
     "start_time": "2024-06-10T08:48:10.595421500Z"
    }
   },
   "id": "d9eda85fac8829d3",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataloaders\n",
    "Allows for sequential or random iteration over a dataset or over a subset of data in a dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8f2cccf87dcaa48"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nThe parameter batch_size indicates the size of the mini-batch for Stochastic Gradient Descent, while num_workers indicates the number of processes that PyTorch should use to load the data. It is important to be able to feed the GPU with enough data to keep it busy, otherwise the training will be slow.\\n\\n'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_data,\n",
    "    shuffle = True,\n",
    "    batch_size = 64, #obviously you cab define it somewhere or hard code it here\n",
    "    num_workers = 12 #in this example it has been defined here\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "The parameter batch_size indicates the size of the mini-batch for Stochastic Gradient Descent, while num_workers indicates the number of processes that PyTorch should use to load the data. It is important to be able to feed the GPU with enough data to keep it busy, otherwise the training will be slow.\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T08:54:30.497393Z",
     "start_time": "2024-06-10T08:54:30.449724700Z"
    }
   },
   "id": "67d509bb246e40fb",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import multiprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T08:55:04.454355800Z",
     "start_time": "2024-06-10T08:55:04.326323Z"
    }
   },
   "id": "331f7b5a57ebef5f",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "**By using several processes that are reading data in parallel, PyTorch can increase the GPU usage and the speed of training. A good rule of thumb is to use a number of workers equal to the number of CPUs on the current machine**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b08807c7d72fffbd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of workers is 12\n"
     ]
    }
   ],
   "source": [
    "n_workers = multiprocessing.cpu_count()\n",
    "print(f\"The number of workers is {n_workers}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T08:57:30.071005500Z",
     "start_time": "2024-06-10T08:57:30.013534900Z"
    }
   },
   "id": "6d8c84e5b7a22ccf",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_MultiProcessingDataLoaderIter' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m dataiter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(train_loader)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Get the next batch\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m image_batch, label_batch \u001B[38;5;241m=\u001B[39m \u001B[43mdataiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m()\n",
      "\u001B[1;31mAttributeError\u001B[0m: '_MultiProcessingDataLoaderIter' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Once you have a dataloader, you can easilty loop over all data in one batch.\n",
    "For example, if you want to obtain the next batch, this is what you need to do...\n",
    "\"\"\"\n",
    "for image_batch, label_batch in train_loader:\n",
    "    #Get an iterator from the dataloader\n",
    "    dataiter = iter(train_loader)\n",
    "    # Get the next batch\n",
    "    image_batch, label_batch = dataiter.next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T09:09:44.485717600Z",
     "start_time": "2024-06-10T09:09:30.917933300Z"
    }
   },
   "id": "4285969e1054d861",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting Dataset in PyTorch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "726f529a5a58b910"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainval_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m## Let's keep 80% of the training data for training\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m train_len \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[43mtrainval_data\u001B[49m) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.8\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m## Let's use the remaining for validation\u001B[39;00m\n\u001B[0;32m      5\u001B[0m val_len \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(trainval_data) \u001B[38;5;241m-\u001B[39m train_len\n",
      "\u001B[1;31mNameError\u001B[0m: name 'trainval_data' is not defined"
     ]
    }
   ],
   "source": [
    "## Let's keep 80% of the training data for training\n",
    "train_len = int(len(trainval_data) * 0.8)\n",
    "\n",
    "## Let's use the remaining for validation\n",
    "val_len = len(trainval_data) - train_len\n",
    "\n",
    "## Perform a random split of the train dataset\n",
    "train_subset, val_subset = torch.utils.data.random_split(\n",
    "    trainval_data, [train_len, val_len]\n",
    ")\n",
    "\n",
    "## Now we can use the subsets as normal datasets\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_subset, batch_size = 64, shuffle = True, num_workers = n_workers\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset = val_subset, batch_size = 64, shuffle = False, num_workers = n_workers\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T09:47:17.459073600Z",
     "start_time": "2024-06-10T09:47:17.408464400Z"
    }
   },
   "id": "dcd9ab67ac43759d",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2096aee7324882a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "torchtensor",
   "language": "python",
   "display_name": "TorchTensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
